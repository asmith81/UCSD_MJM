{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43518c1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# docTR Model Evaluation Notebook\n",
    "\n",
    "This notebook demonstrates basic usage of the docTR model for document text recognition.\n",
    "It focuses on direct model usage with clear logging of outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735e174",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Setup and Configuration\n",
    "### Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies from requirements file\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Determine root directory by finding .gitignore and .gitattributes\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Find project root by locating directory containing .gitignore and .gitattributes\"\"\"\n",
    "    try:\n",
    "        # When running as a script, start from script location\n",
    "        start_path = Path(__file__).parent\n",
    "    except NameError:\n",
    "        # When running in a notebook, start from current working directory\n",
    "        start_path = Path.cwd()\n",
    "    \n",
    "    # Walk up the directory tree to find git markers\n",
    "    current_path = start_path\n",
    "    while current_path != current_path.parent:  # Stop at filesystem root\n",
    "        if (current_path / \".gitignore\").exists() and (current_path / \".gitattributes\").exists():\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    raise RuntimeError(\"Could not find project root (directory containing .gitignore and .gitattributes)\")\n",
    "\n",
    "ROOT_DIR = find_project_root()\n",
    "\n",
    "# Verify expected files exist in the Deliverables-Code directory\n",
    "deliverables_dir = ROOT_DIR / \"Deliverables-Code\"\n",
    "if not deliverables_dir.exists():\n",
    "    raise RuntimeError(\"Could not find Deliverables-Code directory in project root\")\n",
    "\n",
    "def install_doctr_dependencies():\n",
    "    \"\"\"Install docTR dependencies with PyTorch version checking.\"\"\"\n",
    "    requirements_file = ROOT_DIR / \"Deliverables-Code\" / \"requirements\" / \"requirements_doctr.txt\"\n",
    "    \n",
    "    if not requirements_file.exists():\n",
    "        raise FileNotFoundError(f\"Requirements file not found at {requirements_file}\")\n",
    "    \n",
    "    # Check if PyTorch is already installed with correct version\n",
    "    pytorch_compatible = False\n",
    "    try:\n",
    "        import torch\n",
    "        torch_version = torch.__version__\n",
    "        if torch_version.startswith(\"2.1.0\"):\n",
    "            print(f\"Compatible PyTorch {torch_version} already installed\")\n",
    "            pytorch_compatible = True\n",
    "        else:\n",
    "            print(f\"PyTorch {torch_version} found but may need update for docTR compatibility\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not found, will install from requirements\")\n",
    "    \n",
    "    print(f\"Installing docTR dependencies from {requirements_file}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(requirements_file)])\n",
    "        print(\"✅ Dependencies installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Error installing dependencies: {e}\")\n",
    "        raise\n",
    "\n",
    "# Install dependencies\n",
    "install_doctr_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in Python modules\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# External dependencies\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# docTR specific imports\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99afb41",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## CUDA Availability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c19b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cuda_availability() -> bool:\n",
    "    \"\"\"\n",
    "    Check if CUDA is available and log the GPU information.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if CUDA is available, False otherwise\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # Convert to GB\n",
    "        \n",
    "        print(f\"CUDA is available with {gpu_count} GPU(s)\")\n",
    "        print(f\"Using GPU: {gpu_name}\")\n",
    "        print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"CUDA is not available. Running on CPU mode.\")\n",
    "        return False\n",
    "\n",
    "# Check CUDA availability\n",
    "check_cuda_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d876fd0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Model Configuration and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24289a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to store selected model architectures\n",
    "SELECTED_DET_ARCH = None\n",
    "SELECTED_RECO_ARCH = None\n",
    "\n",
    "def select_detection_architecture() -> str:\n",
    "    \"\"\"\n",
    "    Allow user to select a detection architecture.\n",
    "    \n",
    "    Returns:\n",
    "        str: Selected detection architecture\n",
    "    \"\"\"\n",
    "    detection_options = {\n",
    "        1: \"db_resnet50\",\n",
    "        2: \"db_mobilenet_v3_large\", \n",
    "        3: \"linknet_resnet18\",\n",
    "        4: \"linknet_resnet34\",\n",
    "        5: \"linknet_resnet50\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAvailable Detection Architectures:\")\n",
    "    for i, arch in detection_options.items():\n",
    "        print(f\"{i}. {arch}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(f\"\\nSelect detection architecture (1-{len(detection_options)}) [default: 1]: \") or \"1\")\n",
    "            if 1 <= choice <= len(detection_options):\n",
    "                selected_arch = detection_options[choice]\n",
    "                print(f\"Selected detection architecture: {selected_arch}\")\n",
    "                return selected_arch\n",
    "            else:\n",
    "                print(f\"Invalid choice. Please select a number between 1 and {len(detection_options)}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")\n",
    "\n",
    "def select_recognition_architecture() -> str:\n",
    "    \"\"\"\n",
    "    Allow user to select a recognition architecture.\n",
    "    \n",
    "    Returns:\n",
    "        str: Selected recognition architecture\n",
    "    \"\"\"\n",
    "    recognition_options = {\n",
    "        1: \"crnn_vgg16_bn\",\n",
    "        2: \"crnn_mobilenet_v3_small\",\n",
    "        3: \"crnn_mobilenet_v3_large\",\n",
    "        4: \"master\",\n",
    "        5: \"sar_resnet31\",\n",
    "        6: \"vitstr_small\",\n",
    "        7: \"vitstr_base\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAvailable Recognition Architectures:\")\n",
    "    for i, arch in recognition_options.items():\n",
    "        print(f\"{i}. {arch}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(f\"\\nSelect recognition architecture (1-{len(recognition_options)}) [default: 1]: \") or \"1\")\n",
    "            if 1 <= choice <= len(recognition_options):\n",
    "                selected_arch = recognition_options[choice]\n",
    "                print(f\"Selected recognition architecture: {selected_arch}\")\n",
    "                return selected_arch\n",
    "            else:\n",
    "                print(f\"Invalid choice. Please select a number between 1 and {len(recognition_options)}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")\n",
    "\n",
    "# Select model architectures\n",
    "SELECTED_DET_ARCH = select_detection_architecture()\n",
    "SELECTED_RECO_ARCH = select_recognition_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f49035",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9179d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model() -> tuple:\n",
    "    \"\"\"\n",
    "    Initialize docTR OCR model with user-selected architectures.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, device)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nInitializing docTR model...\")\n",
    "        print(f\"Detection Architecture: {SELECTED_DET_ARCH}\")\n",
    "        print(f\"Recognition Architecture: {SELECTED_RECO_ARCH}\")\n",
    "        \n",
    "        # Initialize model with selected architectures\n",
    "        model = ocr_predictor(\n",
    "            det_arch=SELECTED_DET_ARCH,\n",
    "            reco_arch=SELECTED_RECO_ARCH,\n",
    "            pretrained=True,\n",
    "            resolve_blocks=True\n",
    "        )\n",
    "        \n",
    "        # Move model to appropriate device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if device.type == \"cuda\":\n",
    "            model.det_predictor.to(device)\n",
    "            model.reco_predictor.to(device)\n",
    "            print(f\"Model moved to {device}\")\n",
    "        \n",
    "        print(\"Model initialized successfully\")\n",
    "        return model, device\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing model: {e}\")\n",
    "        raise\n",
    "\n",
    "# Initialize the model\n",
    "model, device = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75a71e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Process Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b2567",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_single_image(image_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Process a single image using docTR model and display results.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nProcessing image: {image_path}\")\n",
    "        \n",
    "        # Load and display the image\n",
    "        print(\"Loading and displaying image...\")\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Create a display version of the image with a max size of 800x800\n",
    "        display_image = image.copy()\n",
    "        max_display_size = (800, 800)\n",
    "        display_image.thumbnail(max_display_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Display the image\n",
    "        print(\"\\nInput Image (resized for display):\")\n",
    "        display(display_image)\n",
    "        \n",
    "        # Load image using DocumentFile\n",
    "        print(\"\\nLoading image with DocumentFile...\")\n",
    "        doc = DocumentFile.from_images(image_path)\n",
    "        print(f\"Document loaded successfully\")\n",
    "        \n",
    "        # Run inference\n",
    "        print(\"\\nRunning inference...\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            result = model(doc)\n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"Inference completed in {processing_time:.2f} seconds\")\n",
    "        \n",
    "        # Add rendered text output for easy comparison\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RENDERED TEXT OUTPUT\")\n",
    "        print(\"=\"*50)\n",
    "        rendered_text = result.render()\n",
    "        print(rendered_text)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Store result globally for post-processing\n",
    "        global last_result\n",
    "        last_result = result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059c4b1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Test with Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1d910",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Test with a sample image\n",
    "test_image_path = ROOT_DIR / \"Deliverables-Code\" / \"data\" / \"images\" / \"1_curated\" / \"1017.jpg\"\n",
    "if test_image_path.exists():\n",
    "    process_single_image(str(test_image_path))\n",
    "else:\n",
    "    print(f\"Test image not found at {test_image_path}\")\n",
    "    print(\"Please ensure the image file exists at the specified path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652fe25",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Post-Process Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6754261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_work_order_and_total(result) -> dict:\n",
    "    \"\"\"\n",
    "    Extract work order number and total cost from docTR result using document type classification\n",
    "    and targeted spatial analysis.\n",
    "    \n",
    "    Args:\n",
    "        result: docTR result object\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted data with work_order_number and total_cost\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert result to JSON for easier processing\n",
    "        json_result = result.export()\n",
    "        \n",
    "        extracted_data = {\n",
    "            \"work_order_number\": None,\n",
    "            \"total_cost\": None,\n",
    "            \"extraction_confidence\": {\n",
    "                \"work_order_found\": False,\n",
    "                \"total_cost_found\": False,\n",
    "                \"spatial_match\": False,\n",
    "                \"document_type\": None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        def get_block_info(block):\n",
    "            \"\"\"Extract block information including text and spatial coordinates.\"\"\"\n",
    "            block_words = []\n",
    "            for line in block['lines']:\n",
    "                for word in line['words']:\n",
    "                    block_words.append(word)\n",
    "            \n",
    "            if not block_words:\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Calculate block center point for better spatial comparison\n",
    "            all_coords = []\n",
    "            for word in block_words:\n",
    "                coords = word['geometry']\n",
    "                all_coords.extend(coords)\n",
    "            \n",
    "            if not all_coords:\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Calculate center point\n",
    "            center_x = sum(coord[0] for coord in all_coords) / len(all_coords)\n",
    "            center_y = sum(coord[1] for coord in all_coords) / len(all_coords)\n",
    "            \n",
    "            # Get block text\n",
    "            block_text = ' '.join(word['value'] for word in block_words)\n",
    "            \n",
    "            return block_words, block_text, center_x, center_y\n",
    "        \n",
    "        def fuzzy_contains(text, target_words, threshold=0.7):\n",
    "            \"\"\"Check if text contains target words with OCR error tolerance.\"\"\"\n",
    "            text_lower = text.lower()\n",
    "            \n",
    "            # Direct substring check first (fastest)\n",
    "            if all(word.lower() in text_lower for word in target_words):\n",
    "                return True\n",
    "            \n",
    "            # Character substitution tolerance for common OCR errors\n",
    "            ocr_substitutions = {\n",
    "                'o': '0', '0': 'o', 'i': '1', '1': 'i', 'l': '1', '1': 'l',\n",
    "                's': '5', '5': 's', 'g': '9', '9': 'g', 't': 'f', 'f': 't'\n",
    "            }\n",
    "            \n",
    "            # Create variations of target words\n",
    "            for target in target_words:\n",
    "                variations = [target.lower()]\n",
    "                for i, char in enumerate(target.lower()):\n",
    "                    if char in ocr_substitutions:\n",
    "                        new_word = target.lower()[:i] + ocr_substitutions[char] + target.lower()[i+1:]\n",
    "                        variations.append(new_word)\n",
    "                \n",
    "                # Check if any variation is found\n",
    "                found = False\n",
    "                for var in variations:\n",
    "                    if var in text_lower:\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    return False\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        def classify_document_type(all_blocks):\n",
    "            \"\"\"Determine if document is Invoice or Estimate based on top content.\"\"\"\n",
    "            # Check blocks in the top third of the document\n",
    "            top_blocks = []\n",
    "            for block in all_blocks:\n",
    "                _, block_text, _, center_y = get_block_info(block)\n",
    "                if block_text and center_y < 0.33:  # Top third\n",
    "                    top_blocks.append(block_text.lower())\n",
    "            \n",
    "            top_content = ' '.join(top_blocks)\n",
    "            \n",
    "            # Check for document type indicators\n",
    "            if fuzzy_contains(top_content, ['invoice']):\n",
    "                return 'invoice'\n",
    "            elif fuzzy_contains(top_content, ['estimate']):\n",
    "                return 'estimate'\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        def find_primary_key_invoice(all_blocks):\n",
    "            \"\"\"Find work order number in invoice documents.\"\"\"\n",
    "            for block in all_blocks:\n",
    "                block_words, block_text, center_x, center_y = get_block_info(block)\n",
    "                if not block_words:\n",
    "                    continue\n",
    "                \n",
    "                # Look for MJM Work Order Number pattern\n",
    "                if fuzzy_contains(block_text, ['mjm', 'work', 'order', 'number']) or \\\n",
    "                   fuzzy_contains(block_text, ['mjm', 'order', 'number']):\n",
    "                    \n",
    "                    # First check within the same block for numbers\n",
    "                    for word in block_words:\n",
    "                        word_text = word['value'].strip()\n",
    "                        if word_text.isdigit() and 4 <= len(word_text) <= 6:\n",
    "                            return word_text\n",
    "                    \n",
    "                    # Then look for numbers to the right and nearby\n",
    "                    candidates = []\n",
    "                    for other_block in all_blocks:\n",
    "                        other_words, other_text, other_x, other_y = get_block_info(other_block)\n",
    "                        if not other_words:\n",
    "                            continue\n",
    "                        \n",
    "                        # Calculate distance and position\n",
    "                        distance = ((other_x - center_x) ** 2 + (other_y - center_y) ** 2) ** 0.5\n",
    "                        if distance <= 0.2:  # Within reasonable distance\n",
    "                            for word in other_words:\n",
    "                                word_text = word['value'].strip()\n",
    "                                if word_text.isdigit() and 4 <= len(word_text) <= 6:\n",
    "                                    candidates.append({\n",
    "                                        'value': word_text,\n",
    "                                        'distance': distance,\n",
    "                                        'same_line': abs(other_y - center_y) < 0.05,\n",
    "                                        'to_right': other_x > center_x\n",
    "                                    })\n",
    "                    \n",
    "                    # Sort by preference: same line and to the right, then by distance\n",
    "                    candidates.sort(key=lambda x: (\n",
    "                        not x['same_line'],\n",
    "                        not x['to_right'],\n",
    "                        x['distance']\n",
    "                    ))\n",
    "                    \n",
    "                    if candidates:\n",
    "                        return candidates[0]['value']\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        def find_primary_key_estimate(all_blocks):\n",
    "            \"\"\"Find estimate number in estimate documents.\"\"\"\n",
    "            for block in all_blocks:\n",
    "                block_words, block_text, center_x, center_y = get_block_info(block)\n",
    "                if not block_words:\n",
    "                    continue\n",
    "                \n",
    "                # Look for Estimate Number pattern\n",
    "                if fuzzy_contains(block_text, ['estimate', 'number']):\n",
    "                    \n",
    "                    # First check within the same block\n",
    "                    for word in block_words:\n",
    "                        word_text = word['value'].strip()\n",
    "                        if word_text.isdigit() and 4 <= len(word_text) <= 6:\n",
    "                            return word_text\n",
    "                    \n",
    "                    # Look for numbers below and nearby\n",
    "                    candidates = []\n",
    "                    for other_block in all_blocks:\n",
    "                        other_words, other_text, other_x, other_y = get_block_info(other_block)\n",
    "                        if not other_words:\n",
    "                            continue\n",
    "                        \n",
    "                        # Calculate distance and position\n",
    "                        distance = ((other_x - center_x) ** 2 + (other_y - center_y) ** 2) ** 0.5\n",
    "                        if distance <= 0.2:  # Within reasonable distance\n",
    "                            for word in other_words:\n",
    "                                word_text = word['value'].strip()\n",
    "                                if word_text.isdigit() and 4 <= len(word_text) <= 6:\n",
    "                                    candidates.append({\n",
    "                                        'value': word_text,\n",
    "                                        'distance': distance,\n",
    "                                        'below': other_y > center_y,\n",
    "                                        'nearby_x': abs(other_x - center_x) < 0.1\n",
    "                                    })\n",
    "                    \n",
    "                    # Sort by preference: below and nearby horizontally, then by distance\n",
    "                    candidates.sort(key=lambda x: (\n",
    "                        not x['below'],\n",
    "                        not x['nearby_x'],\n",
    "                        x['distance']\n",
    "                    ))\n",
    "                    \n",
    "                    if candidates:\n",
    "                        return candidates[0]['value']\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        def find_grand_total(all_blocks):\n",
    "            \"\"\"Find grand total amount with emphasis on lower portion of document.\"\"\"\n",
    "            # First, identify blocks in the lower portion (bottom half)\n",
    "            lower_blocks = []\n",
    "            for block in all_blocks:\n",
    "                _, block_text, center_x, center_y = get_block_info(block)\n",
    "                if center_y > 0.5:  # Lower half\n",
    "                    lower_blocks.append((block, center_x, center_y))\n",
    "            \n",
    "            # If we have lower blocks, prioritize them\n",
    "            target_blocks = lower_blocks if lower_blocks else [(block, *get_block_info(block)[2:4]) for block in all_blocks]\n",
    "            \n",
    "            for block, center_x, center_y in target_blocks:\n",
    "                block_words, block_text, _, _ = get_block_info(block)\n",
    "                if not block_words:\n",
    "                    continue\n",
    "                \n",
    "                # Look for Grand Total pattern\n",
    "                if fuzzy_contains(block_text, ['grand', 'total']) or \\\n",
    "                   fuzzy_contains(block_text, ['total']):\n",
    "                    \n",
    "                    # Check within the same block first\n",
    "                    monetary_candidates = []\n",
    "                    for word in block_words:\n",
    "                        word_text = word['value'].strip()\n",
    "                        clean_amount = extract_monetary_value(word_text)\n",
    "                        if clean_amount:\n",
    "                            monetary_candidates.append({\n",
    "                                'value': clean_amount,\n",
    "                                'distance': 0,\n",
    "                                'same_block': True\n",
    "                            })\n",
    "                    \n",
    "                    # Look for monetary values to the right and nearby\n",
    "                    for other_block in all_blocks:\n",
    "                        other_words, other_text, other_x, other_y = get_block_info(other_block)\n",
    "                        if not other_words or other_block == block:\n",
    "                            continue\n",
    "                        \n",
    "                        distance = ((other_x - center_x) ** 2 + (other_y - center_y) ** 2) ** 0.5\n",
    "                        if distance <= 0.2:  # Within reasonable distance\n",
    "                            for word in other_words:\n",
    "                                word_text = word['value'].strip()\n",
    "                                clean_amount = extract_monetary_value(word_text)\n",
    "                                if clean_amount:\n",
    "                                    monetary_candidates.append({\n",
    "                                        'value': clean_amount,\n",
    "                                        'distance': distance,\n",
    "                                        'same_block': False,\n",
    "                                        'to_right': other_x > center_x,\n",
    "                                        'same_line': abs(other_y - center_y) < 0.05\n",
    "                                    })\n",
    "                    \n",
    "                    # Sort by preference\n",
    "                    monetary_candidates.sort(key=lambda x: (\n",
    "                        not x.get('same_block', False),\n",
    "                        not x.get('same_line', False),\n",
    "                        not x.get('to_right', False),\n",
    "                        x['distance']\n",
    "                    ))\n",
    "                    \n",
    "                    if monetary_candidates:\n",
    "                        return monetary_candidates[0]['value']\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        def extract_monetary_value(text):\n",
    "            \"\"\"Extract clean monetary value from text.\"\"\"\n",
    "            if not text:\n",
    "                return None\n",
    "            \n",
    "            # Remove common prefixes and clean up\n",
    "            clean_text = text.replace('$', '').replace(',', '').strip()\n",
    "            \n",
    "            try:\n",
    "                # Try to parse as float\n",
    "                amount = float(clean_text)\n",
    "                \n",
    "                # Reasonable range check (between $10 and $10,000)\n",
    "                if 10.0 <= amount <= 10000.0:\n",
    "                    # Format consistently\n",
    "                    if '.' in clean_text:\n",
    "                        return f\"{amount:.2f}\"\n",
    "                    else:\n",
    "                        # If no decimal, assume whole dollars\n",
    "                        return f\"{amount:.2f}\"\n",
    "                        \n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        # Main processing logic\n",
    "        for page in json_result['pages']:\n",
    "            all_blocks = page['blocks']\n",
    "            \n",
    "            # Step 1: Classify document type\n",
    "            doc_type = classify_document_type(all_blocks)\n",
    "            extracted_data[\"extraction_confidence\"][\"document_type\"] = doc_type\n",
    "            \n",
    "            if doc_type:\n",
    "                extracted_data[\"extraction_confidence\"][\"spatial_match\"] = True\n",
    "            \n",
    "            # Step 2: Extract primary key based on document type\n",
    "            primary_key = None\n",
    "            if doc_type == 'invoice':\n",
    "                primary_key = find_primary_key_invoice(all_blocks)\n",
    "            elif doc_type == 'estimate':\n",
    "                primary_key = find_primary_key_estimate(all_blocks)\n",
    "            else:\n",
    "                # Fallback: try both methods\n",
    "                primary_key = find_primary_key_invoice(all_blocks) or find_primary_key_estimate(all_blocks)\n",
    "            \n",
    "            if primary_key:\n",
    "                extracted_data[\"work_order_number\"] = primary_key\n",
    "                extracted_data[\"extraction_confidence\"][\"work_order_found\"] = True\n",
    "            \n",
    "            # Step 3: Extract total cost\n",
    "            total_cost = find_grand_total(all_blocks)\n",
    "            if total_cost:\n",
    "                extracted_data[\"total_cost\"] = total_cost\n",
    "                extracted_data[\"extraction_confidence\"][\"total_cost_found\"] = True\n",
    "        \n",
    "        return extracted_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in post-processing: {e}\")\n",
    "        return {\n",
    "            \"work_order_number\": None,\n",
    "            \"total_cost\": None,\n",
    "            \"extraction_confidence\": {\n",
    "                \"spatial_extraction_successful\": False,\n",
    "                \"parsing_method\": \"spatial_analysis\",\n",
    "                \"work_order_found\": False,\n",
    "                \"total_cost_found\": False,\n",
    "                \"overall_confidence\": 0.0\n",
    "            },\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def post_process_single_image():\n",
    "    \"\"\"\n",
    "    Post-process the last processed image result to extract structured data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if we have a result to process\n",
    "        if 'last_result' not in globals():\n",
    "            print(\"No image result available. Please run the single image test first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"POST-PROCESSING EXTRACTION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Extract structured data\n",
    "        extracted_data = extract_work_order_and_total(last_result)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nExtracted Data:\")\n",
    "        print(json.dumps(extracted_data, indent=2))\n",
    "        \n",
    "        # Provide user feedback\n",
    "        if extracted_data[\"extraction_confidence\"][\"work_order_found\"]:\n",
    "            print(f\"\\n✅ Work Order Number found: {extracted_data['work_order_number']}\")\n",
    "        else:\n",
    "            print(\"\\n❌ Work Order Number not found\")\n",
    "            \n",
    "        if extracted_data[\"extraction_confidence\"][\"total_cost_found\"]:\n",
    "            print(f\"✅ Total Cost found: ${extracted_data['total_cost']}\")\n",
    "        else:\n",
    "            print(\"❌ Total Cost not found\")\n",
    "            \n",
    "        if extracted_data[\"extraction_confidence\"][\"spatial_match\"]:\n",
    "            print(\"✅ Spatial filtering successful\")\n",
    "        else:\n",
    "            print(\"❌ No spatial matches found\")\n",
    "        \n",
    "        return extracted_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in post-processing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run post-processing on the last result\n",
    "post_process_single_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f72dc",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8821886",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_results_filename(model_name: str, quantization_level: str, results_dir: Path) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Generate a results filename with auto-incrementing counter.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model (e.g., \"pixtral\", \"llama\", \"doctr\")\n",
    "        quantization_level: Quantization level (e.g., \"bfloat16\", \"int8\", \"int4\", \"none\")\n",
    "        results_dir: Directory where results are stored\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (filename_without_extension, full_filepath)\n",
    "    \"\"\"\n",
    "    # Find existing files with the same model and quantization pattern\n",
    "    pattern = f\"results-{model_name}-{quantization_level}-*.json\"\n",
    "    existing_files = list(results_dir.glob(pattern))\n",
    "    \n",
    "    # Extract counter numbers from existing files\n",
    "    counter_numbers = []\n",
    "    for file in existing_files:\n",
    "        try:\n",
    "            # Extract number from filename like \"results-doctr-none-3.json\"\n",
    "            parts = file.stem.split('-')\n",
    "            if len(parts) >= 4:\n",
    "                counter_numbers.append(int(parts[-1]))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # Get next counter number\n",
    "    next_counter = max(counter_numbers, default=0) + 1\n",
    "    \n",
    "    # Generate filename\n",
    "    filename_base = f\"results-{model_name}-{quantization_level}-{next_counter}\"\n",
    "    full_filepath = results_dir / f\"{filename_base}.json\"\n",
    "    \n",
    "    return filename_base, str(full_filepath)\n",
    "\n",
    "def generate_test_id() -> str:\n",
    "    \"\"\"Generate a unique test identifier using timestamp.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def collect_test_metadata(test_id: str) -> dict:\n",
    "    \"\"\"Collect metadata about the current test configuration.\"\"\"\n",
    "    # Get GPU information\n",
    "    gpu_props = torch.cuda.get_device_properties(0) if torch.cuda.is_available() else None\n",
    "    \n",
    "    return {\n",
    "        \"test_id\": test_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model_info\": {\n",
    "            \"name\": \"docTR\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"model_id\": {\n",
    "                \"detection_model\": SELECTED_DET_ARCH,\n",
    "                \"recognition_model\": SELECTED_RECO_ARCH,\n",
    "                \"combined\": f\"{SELECTED_DET_ARCH}+{SELECTED_RECO_ARCH}\"\n",
    "            },\n",
    "            \"model_type\": \"ocr\",\n",
    "            \"quantization\": {\n",
    "                \"type\": \"none\",\n",
    "                \"config\": {}\n",
    "            },\n",
    "            \"device_info\": {\n",
    "                \"device_map\": str(device),\n",
    "                \"use_flash_attention\": False,\n",
    "                \"gpu_memory_gb\": round(gpu_props.total_memory / (1024**3), 2) if gpu_props else None,\n",
    "                \"compute_capability\": f\"{gpu_props.major}.{gpu_props.minor}\" if gpu_props else None\n",
    "            }\n",
    "        },\n",
    "        \"prompt_info\": {\n",
    "            \"prompt_type\": \"N/A\",\n",
    "            \"raw_text\": \"N/A (OCR only)\",\n",
    "            \"formatted_text\": \"N/A (OCR only)\",\n",
    "            \"special_tokens\": []\n",
    "        },\n",
    "        \"processing_config\": {\n",
    "            \"inference_params\": {\n",
    "                \"resolve_blocks\": True,\n",
    "                \"det_arch\": SELECTED_DET_ARCH,\n",
    "                \"reco_arch\": SELECTED_RECO_ARCH\n",
    "            },\n",
    "            \"image_preprocessing\": {\n",
    "                \"max_size\": [1024, 1024],\n",
    "                \"format\": \"RGB\",\n",
    "                \"resize_strategy\": \"maintain_aspect_ratio\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def save_incremental_results(results_file: Path, results: list, metadata: dict):\n",
    "    \"\"\"Save results incrementally to avoid losing progress.\"\"\"\n",
    "    complete_results = {\n",
    "        \"metadata\": metadata,\n",
    "        \"results\": results\n",
    "    }\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(complete_results, f, indent=2)\n",
    "\n",
    "def process_single_image_for_batch(image_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process a single image for batch processing, returning structured results with raw OCR output only.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing results including raw OCR data and metadata\n",
    "    \"\"\"\n",
    "    result_entry = {\n",
    "        \"image_name\": Path(image_path).name,\n",
    "        \"status\": \"processing\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing image: {Path(image_path).name}\")\n",
    "        \n",
    "        # Load image using DocumentFile\n",
    "        doc = DocumentFile.from_images(image_path)\n",
    "        \n",
    "        # Run inference with timing\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            doctr_result = model(doc)\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Get rendered text output\n",
    "        rendered_text = doctr_result.render()\n",
    "        \n",
    "        # Export to JSON for spatial data\n",
    "        json_result = doctr_result.export()\n",
    "        \n",
    "        # Count OCR statistics\n",
    "        total_blocks = sum(len(page['blocks']) for page in json_result['pages'])\n",
    "        total_lines = sum(len(block['lines']) for page in json_result['pages'] for block in page['blocks'])\n",
    "        total_words = sum(len(line['words']) for page in json_result['pages'] for block in page['blocks'] for line in block['lines'])\n",
    "        \n",
    "        # Update result entry with raw OCR output only\n",
    "        result_entry.update({\n",
    "            \"status\": \"completed\",\n",
    "            \"processing_time_seconds\": round(processing_time, 2),\n",
    "            \"raw_output\": {\n",
    "                \"ocr_text\": rendered_text,\n",
    "                \"spatial_data\": json_result,\n",
    "                \"detection_results\": {\n",
    "                    \"blocks_detected\": total_blocks,\n",
    "                    \"lines_detected\": total_lines,\n",
    "                    \"words_detected\": total_words\n",
    "                },\n",
    "                \"page_dimensions\": json_result['pages'][0]['dimensions'] if json_result['pages'] else None\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(f\"✅ Successfully processed {Path(image_path).name}\")\n",
    "        return result_entry\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {Path(image_path).name}: {e}\")\n",
    "        result_entry.update({\n",
    "            \"status\": \"error\",\n",
    "            \"error\": {\n",
    "                \"type\": \"processing_error\",\n",
    "                \"message\": str(e),\n",
    "                \"stage\": \"inference\"\n",
    "            }\n",
    "        })\n",
    "        return result_entry\n",
    "\n",
    "def process_batch(image_dir: str = None, output_dir: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Process a batch of images and save raw OCR results only.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory containing images to process\n",
    "        output_dir (str): Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the results file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up directories\n",
    "        if image_dir is None:\n",
    "            image_dir = ROOT_DIR / \"Deliverables-Code\" / \"data\" / \"images\" / \"1_curated\"\n",
    "        if output_dir is None:\n",
    "            output_dir = ROOT_DIR / \"Deliverables-Code\" / \"results\"\n",
    "        \n",
    "        image_dir = Path(image_dir)\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get list of image files\n",
    "        image_files = []\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']:\n",
    "            image_files.extend(list(image_dir.glob(f'*{ext}')))\n",
    "            image_files.extend(list(image_dir.glob(f'*{ext.upper()}')))\n",
    "        \n",
    "        if not image_files:\n",
    "            raise ValueError(f\"No image files found in {image_dir}\")\n",
    "        \n",
    "        # Generate filename with new naming convention\n",
    "        test_id, results_file_path = generate_results_filename(\"doctr\", \"none\", output_dir)\n",
    "        results_file = Path(results_file_path)\n",
    "        \n",
    "        # Collect metadata with the test_id\n",
    "        metadata = collect_test_metadata(test_id)\n",
    "        \n",
    "        print(f\"\\nStarting docTR batch test\")\n",
    "        print(f\"Found {len(image_files)} images to process\")\n",
    "        print(f\"Results will be saved to: {results_file}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Process each image\n",
    "        results = []\n",
    "        for i, image_path in enumerate(image_files, 1):\n",
    "            print(f\"\\n[{i}/{len(image_files)}] \", end=\"\")\n",
    "            \n",
    "            # Process single image\n",
    "            result = process_single_image_for_batch(str(image_path))\n",
    "            results.append(result)\n",
    "            \n",
    "            # Save incremental results after each image\n",
    "            save_incremental_results(results_file, results, metadata)\n",
    "            \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Batch processing completed!\")\n",
    "        print(f\"Processed: {len([r for r in results if r['status'] == 'completed'])}/{len(results)} images\")\n",
    "        print(f\"Errors: {len([r for r in results if r['status'] == 'error'])}/{len(results)} images\")\n",
    "        print(f\"Raw results saved to: {results_file}\")\n",
    "        \n",
    "        return str(results_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch processing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52353f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch processing\n",
    "test_batch_results = process_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04497c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Analysis Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aad838",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_total_cost(cost_str: str) -> float:\n",
    "    \"\"\"Convert a cost string to a float by removing currency symbols and commas.\"\"\"\n",
    "    if not cost_str:\n",
    "        return None\n",
    "    # If already a float, return as is\n",
    "    if isinstance(cost_str, (int, float)):\n",
    "        return float(cost_str)\n",
    "    # Remove $ and commas, then convert to float\n",
    "    try:\n",
    "        return float(cost_str.replace('$', '').replace(',', '').strip())\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def categorize_work_order_error(predicted: str, ground_truth: str) -> str:\n",
    "    \"\"\"Categorize the type of error in work order number prediction.\"\"\"\n",
    "    if not predicted or not ground_truth:\n",
    "        return \"No Extraction\"\n",
    "    if predicted == ground_truth:\n",
    "        return \"Exact Match\"\n",
    "    # Check if prediction looks like a date (contains - or /)\n",
    "    if '-' in predicted or '/' in predicted:\n",
    "        return \"Date Confusion\"\n",
    "    # Check for partial match (some digits match)\n",
    "    if any(digit in ground_truth for digit in predicted):\n",
    "        return \"Partial Match\"\n",
    "    return \"Completely Wrong\"\n",
    "\n",
    "def categorize_total_cost_error(predicted: float, ground_truth: float) -> str:\n",
    "    \"\"\"Categorize the type of error in total cost prediction.\"\"\"\n",
    "    if predicted is None or ground_truth is None:\n",
    "        return \"No Extraction\"\n",
    "    if predicted == ground_truth:\n",
    "        return \"Numeric Match\"\n",
    "    \n",
    "    # Convert to strings for digit comparison\n",
    "    pred_str = str(int(predicted))\n",
    "    truth_str = str(int(ground_truth))\n",
    "    \n",
    "    # Check for digit reversal\n",
    "    if pred_str[::-1] == truth_str:\n",
    "        return \"Digit Reversal\"\n",
    "    \n",
    "    # Check for missing digit\n",
    "    if len(pred_str) == len(truth_str) - 1 and all(d in truth_str for d in pred_str):\n",
    "        return \"Missing Digit\"\n",
    "    \n",
    "    # Check for extra digit\n",
    "    if len(pred_str) == len(truth_str) + 1 and all(d in pred_str for d in truth_str):\n",
    "        return \"Extra Digit\"\n",
    "    \n",
    "    return \"Completely Wrong\"\n",
    "\n",
    "def calculate_cer(str1: str, str2: str) -> float:\n",
    "    \"\"\"Calculate Character Error Rate between two strings.\"\"\"\n",
    "    if not str1 or not str2:\n",
    "        return 1.0  # Return maximum error if either string is empty\n",
    "    \n",
    "    # Convert to strings and remove whitespace\n",
    "    str1 = str(str1).strip()\n",
    "    str2 = str(str2).strip()\n",
    "    \n",
    "    # Calculate Levenshtein distance\n",
    "    if len(str1) < len(str2):\n",
    "        str1, str2 = str2, str1\n",
    "    \n",
    "    if len(str2) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    previous_row = range(len(str2) + 1)\n",
    "    for i, c1 in enumerate(str1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(str2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    # Return CER as distance divided by length of longer string\n",
    "    return previous_row[-1] / len(str1)\n",
    "\n",
    "def select_test_results_file() -> Path:\n",
    "    \"\"\"Allow user to select a test results file for analysis.\"\"\"\n",
    "    # Get all test result files\n",
    "    results_dir_path = ROOT_DIR / \"Deliverables-Code\" / \"results\"\n",
    "    result_files = list(results_dir_path.glob(\"results-doctr-*.json\"))\n",
    "    \n",
    "    if not result_files:\n",
    "        raise FileNotFoundError(\"No docTR test result files found in results directory\")\n",
    "    \n",
    "    # Sort files by modification time (newest first)\n",
    "    result_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    print(\"\\nAvailable test result files:\")\n",
    "    for i, file in enumerate(result_files, 1):\n",
    "        # Get file modification time\n",
    "        mod_time = datetime.fromtimestamp(file.stat().st_mtime)\n",
    "        print(f\"{i}. {file.name} (Modified: {mod_time.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"\\nSelect a test result file (1-{}): \".format(len(result_files))))\n",
    "            if 1 <= choice <= len(result_files):\n",
    "                selected_file = result_files[choice - 1]\n",
    "                print(f\"\\nSelected file: {selected_file.name}\")\n",
    "                return selected_file\n",
    "            else:\n",
    "                print(f\"Invalid choice. Please select a number between 1 and {len(result_files)}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ca97a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Analysis Functions - Data Processing Phase\n",
    "Functions for analyzing raw OCR outputs and generating structured analysis reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47b6da",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_raw_results(results_file: str, ground_truth_file: str = None) -> dict:\n",
    "    \"\"\"Analyze raw OCR results and generate analysis report.\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Set default ground truth file path\n",
    "    if ground_truth_file is None:\n",
    "        ground_truth_file = str(ROOT_DIR / \"Deliverables-Code\" / \"data\" / \"images\" / \"metadata\" / \"ground_truth.csv\")\n",
    "    \n",
    "    # Load results and ground truth\n",
    "    with open(results_file, 'r') as f:\n",
    "        raw_results = json.load(f)\n",
    "    \n",
    "    # Read ground truth with explicit string type for filename column\n",
    "    ground_truth = pd.read_csv(ground_truth_file, dtype={'filename': str})\n",
    "    \n",
    "    # Initialize analysis structure\n",
    "    analysis = {\n",
    "        \"source_results\": results_file,\n",
    "        \"extraction_method\": \"spatial_analysis_v2\",\n",
    "        \"ground_truth_file\": ground_truth_file,\n",
    "        \"metadata\": raw_results[\"metadata\"],\n",
    "        \"summary\": {\n",
    "            \"total_images\": len(raw_results[\"results\"]),\n",
    "            \"completed\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"spatial_extraction_successful\": 0,\n",
    "            \"work_order_accuracy\": 0,\n",
    "            \"total_cost_accuracy\": 0,\n",
    "            \"average_cer\": 0,\n",
    "            \"document_type_detection\": {\n",
    "                \"invoice_detected\": 0,\n",
    "                \"estimate_detected\": 0,\n",
    "                \"type_unknown\": 0\n",
    "            },\n",
    "            \"confidence_analysis\": {\n",
    "                \"spatial_match_rate\": 0,\n",
    "                \"work_order_confidence_accuracy\": 0,\n",
    "                \"total_cost_confidence_accuracy\": 0\n",
    "            }\n",
    "        },\n",
    "        \"error_categories\": {\n",
    "            \"work_order\": {},\n",
    "            \"total_cost\": {}\n",
    "        },\n",
    "        \"document_type_performance\": {\n",
    "            \"invoice\": {\"work_order_accuracy\": 0, \"total_cost_accuracy\": 0, \"count\": 0},\n",
    "            \"estimate\": {\"work_order_accuracy\": 0, \"total_cost_accuracy\": 0, \"count\": 0},\n",
    "            \"unknown\": {\"work_order_accuracy\": 0, \"total_cost_accuracy\": 0, \"count\": 0}\n",
    "        },\n",
    "        \"extracted_data\": [],\n",
    "        \"performance_metrics\": {}\n",
    "    }\n",
    "    \n",
    "    # Process each result\n",
    "    total_cer = 0\n",
    "    work_order_matches = 0\n",
    "    total_cost_matches = 0\n",
    "    spatial_successful = 0\n",
    "    spatial_match_count = 0\n",
    "    confidence_work_order_correct = 0\n",
    "    confidence_total_cost_correct = 0\n",
    "    \n",
    "    # Document type counters\n",
    "    doc_type_counts = {\"invoice\": 0, \"estimate\": 0, \"unknown\": 0}\n",
    "    doc_type_work_order_matches = {\"invoice\": 0, \"estimate\": 0, \"unknown\": 0}\n",
    "    doc_type_total_cost_matches = {\"invoice\": 0, \"estimate\": 0, \"unknown\": 0}\n",
    "    \n",
    "    for result in raw_results[\"results\"]:\n",
    "        # Get ground truth for this image - use filename directly for matching\n",
    "        image_filename = result[\"image_name\"]\n",
    "        \n",
    "        gt_row = ground_truth[ground_truth[\"filename\"] == image_filename]\n",
    "        \n",
    "        if gt_row.empty:\n",
    "            logger.warning(f\"No ground truth found for image {image_filename}\")\n",
    "            continue\n",
    "            \n",
    "        gt_work_order = str(gt_row[\"work_order_number\"].iloc[0]).strip()\n",
    "        gt_total_cost = normalize_total_cost(str(gt_row[\"total\"].iloc[0]))\n",
    "        # Note: Ground truth CSV doesn't have a Type column, so we can't validate document type detection\n",
    "        gt_doc_type = \"unknown\"  # Default since we don't have ground truth document types\n",
    "        \n",
    "        # Initialize extraction entry\n",
    "        extraction_entry = {\n",
    "            \"image_name\": result[\"image_name\"],\n",
    "            \"status\": result[\"status\"],\n",
    "            \"raw_ocr_text\": result.get(\"raw_output\", {}).get(\"ocr_text\", \"\"),\n",
    "            \"spatial_data\": result.get(\"raw_output\", {}).get(\"spatial_data\", {}),\n",
    "            \"ground_truth\": {\n",
    "                \"work_order_number\": gt_work_order,\n",
    "                \"total_cost\": gt_total_cost,\n",
    "                \"document_type\": gt_doc_type\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if result[\"status\"] == \"completed\":\n",
    "            analysis[\"summary\"][\"completed\"] += 1\n",
    "            \n",
    "            # Extract structured data from spatial data\n",
    "            spatial_data = result[\"raw_output\"][\"spatial_data\"]\n",
    "            extracted_data = extract_work_order_and_total(spatial_data)\n",
    "            \n",
    "            if extracted_data and not extracted_data.get(\"error\"):\n",
    "                spatial_successful += 1\n",
    "                \n",
    "                # Get confidence info\n",
    "                confidence_info = extracted_data[\"extraction_confidence\"]\n",
    "                \n",
    "                # Document type analysis\n",
    "                detected_type = confidence_info.get(\"document_type\", \"unknown\")\n",
    "                if detected_type == \"invoice\":\n",
    "                    analysis[\"summary\"][\"document_type_detection\"][\"invoice_detected\"] += 1\n",
    "                elif detected_type == \"estimate\":\n",
    "                    analysis[\"summary\"][\"document_type_detection\"][\"estimate_detected\"] += 1\n",
    "                else:\n",
    "                    analysis[\"summary\"][\"document_type_detection\"][\"type_unknown\"] += 1\n",
    "                \n",
    "                # Count document types for performance analysis\n",
    "                doc_type_key = detected_type if detected_type else \"unknown\"\n",
    "                doc_type_counts[doc_type_key] += 1\n",
    "                \n",
    "                # Spatial match analysis\n",
    "                if confidence_info.get(\"spatial_match\", False):\n",
    "                    spatial_match_count += 1\n",
    "                \n",
    "                # Analyze work order\n",
    "                pred_work_order = extracted_data.get(\"work_order_number\", \"\")\n",
    "                work_order_error = categorize_work_order_error(pred_work_order, gt_work_order)\n",
    "                work_order_cer = calculate_cer(pred_work_order, gt_work_order)\n",
    "                \n",
    "                work_order_correct = work_order_error == \"Exact Match\"\n",
    "                if work_order_correct:\n",
    "                    work_order_matches += 1\n",
    "                    doc_type_work_order_matches[doc_type_key] += 1\n",
    "                \n",
    "                # Confidence vs accuracy analysis for work order\n",
    "                if confidence_info.get(\"work_order_found\", False) and work_order_correct:\n",
    "                    confidence_work_order_correct += 1\n",
    "                \n",
    "                # Analyze total cost\n",
    "                pred_total_cost = normalize_total_cost(extracted_data.get(\"total_cost\", \"\"))\n",
    "                total_cost_error = categorize_total_cost_error(pred_total_cost, gt_total_cost)\n",
    "                \n",
    "                total_cost_correct = total_cost_error == \"Numeric Match\"\n",
    "                if total_cost_correct:\n",
    "                    total_cost_matches += 1\n",
    "                    doc_type_total_cost_matches[doc_type_key] += 1\n",
    "                \n",
    "                # Confidence vs accuracy analysis for total cost\n",
    "                if confidence_info.get(\"total_cost_found\", False) and total_cost_correct:\n",
    "                    confidence_total_cost_correct += 1\n",
    "                \n",
    "                # Update extraction entry\n",
    "                extraction_entry.update({\n",
    "                    \"extracted_data\": {\n",
    "                        \"work_order_number\": pred_work_order,\n",
    "                        \"total_cost\": pred_total_cost,\n",
    "                        \"document_type\": detected_type\n",
    "                    },\n",
    "                    \"extraction_confidence\": confidence_info,\n",
    "                    \"performance\": {\n",
    "                        \"work_order_error_category\": work_order_error,\n",
    "                        \"total_cost_error_category\": total_cost_error,\n",
    "                        \"work_order_cer\": work_order_cer,\n",
    "                        \"work_order_correct\": work_order_correct,\n",
    "                        \"total_cost_correct\": total_cost_correct,\n",
    "                        \"type_match\": detected_type == gt_doc_type\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                # Update error categories\n",
    "                analysis[\"error_categories\"][\"work_order\"][work_order_error] = \\\n",
    "                    analysis[\"error_categories\"][\"work_order\"].get(work_order_error, 0) + 1\n",
    "                analysis[\"error_categories\"][\"total_cost\"][total_cost_error] = \\\n",
    "                    analysis[\"error_categories\"][\"total_cost\"].get(total_cost_error, 0) + 1\n",
    "                \n",
    "                total_cer += work_order_cer\n",
    "            else:\n",
    "                extraction_entry.update({\n",
    "                    \"extraction_error\": extracted_data.get(\"error\", \"Spatial extraction failed\"),\n",
    "                    \"extraction_confidence\": {\n",
    "                        \"spatial_extraction_successful\": False,\n",
    "                        \"parsing_method\": \"spatial_analysis\",\n",
    "                        \"work_order_found\": False,\n",
    "                        \"total_cost_found\": False,\n",
    "                        \"overall_confidence\": 0.0\n",
    "                    }\n",
    "                })\n",
    "        else:\n",
    "            analysis[\"summary\"][\"errors\"] += 1\n",
    "            extraction_entry[\"processing_error\"] = result.get(\"error\", {})\n",
    "        \n",
    "        analysis[\"extracted_data\"].append(extraction_entry)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    completed = analysis[\"summary\"][\"completed\"]\n",
    "    if completed > 0:\n",
    "        analysis[\"summary\"][\"spatial_extraction_successful\"] = spatial_successful\n",
    "        analysis[\"summary\"][\"work_order_accuracy\"] = work_order_matches / completed\n",
    "        analysis[\"summary\"][\"total_cost_accuracy\"] = total_cost_matches / completed\n",
    "        analysis[\"summary\"][\"average_cer\"] = total_cer / completed\n",
    "        analysis[\"summary\"][\"confidence_analysis\"][\"spatial_match_rate\"] = spatial_match_count / completed\n",
    "        \n",
    "        # Confidence accuracy rates\n",
    "        work_order_confident_count = sum(1 for e in analysis[\"extracted_data\"] \n",
    "                                       if e.get(\"extraction_confidence\", {}).get(\"work_order_found\", False))\n",
    "        total_cost_confident_count = sum(1 for e in analysis[\"extracted_data\"] \n",
    "                                       if e.get(\"extraction_confidence\", {}).get(\"total_cost_found\", False))\n",
    "        \n",
    "        if work_order_confident_count > 0:\n",
    "            analysis[\"summary\"][\"confidence_analysis\"][\"work_order_confidence_accuracy\"] = confidence_work_order_correct / work_order_confident_count\n",
    "        if total_cost_confident_count > 0:\n",
    "            analysis[\"summary\"][\"confidence_analysis\"][\"total_cost_confidence_accuracy\"] = confidence_total_cost_correct / total_cost_confident_count\n",
    "        \n",
    "        # Performance metrics\n",
    "        analysis[\"performance_metrics\"] = {\n",
    "            \"spatial_extraction_rate\": spatial_successful / completed,\n",
    "            \"work_order_extraction_rate\": work_order_matches / completed,\n",
    "            \"total_cost_extraction_rate\": total_cost_matches / completed,\n",
    "            \"average_processing_time\": sum(\n",
    "                r.get(\"processing_time_seconds\", 0) \n",
    "                for r in raw_results[\"results\"] \n",
    "                if r[\"status\"] == \"completed\"\n",
    "            ) / completed\n",
    "        }\n",
    "    \n",
    "    # Calculate document type performance\n",
    "    for doc_type in [\"invoice\", \"estimate\", \"unknown\"]:\n",
    "        count = doc_type_counts[doc_type]\n",
    "        if count > 0:\n",
    "            analysis[\"document_type_performance\"][doc_type] = {\n",
    "                \"work_order_accuracy\": doc_type_work_order_matches[doc_type] / count,\n",
    "                \"total_cost_accuracy\": doc_type_total_cost_matches[doc_type] / count,\n",
    "                \"count\": count\n",
    "            }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def run_analysis():\n",
    "    \"\"\"Run analysis on raw OCR results and generate comprehensive performance report.\"\"\"\n",
    "    try:\n",
    "        # Get test results file\n",
    "        results_file = select_test_results_file()\n",
    "        \n",
    "        # Generate analysis\n",
    "        analysis = analyze_raw_results(str(results_file))\n",
    "        \n",
    "        # Create analysis directory if it doesn't exist\n",
    "        analysis_dir = ROOT_DIR / \"Deliverables-Code\" / \"analysis\"\n",
    "        analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Generate analysis filename with same convention as results\n",
    "        model_name = \"doctr\"\n",
    "        quantization_level = \"none\"  # docTR doesn't use quantization\n",
    "        \n",
    "        # Find existing analysis files with the same model and quantization pattern\n",
    "        pattern = f\"analysis-{model_name}-{quantization_level}-*.json\"\n",
    "        existing_files = list(analysis_dir.glob(pattern))\n",
    "        \n",
    "        # Extract counter numbers from existing files\n",
    "        counter_numbers = []\n",
    "        for file in existing_files:\n",
    "            try:\n",
    "                # Extract number from filename like \"analysis-doctr-none-3.json\"\n",
    "                parts = file.stem.split('-')\n",
    "                if len(parts) >= 4:\n",
    "                    counter_numbers.append(int(parts[-1]))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # Get next counter number\n",
    "        next_counter = max(counter_numbers, default=0) + 1\n",
    "        \n",
    "        # Generate analysis filename\n",
    "        analysis_filename = f\"analysis-{model_name}-{quantization_level}-{next_counter}.json\"\n",
    "        analysis_file = analysis_dir / analysis_filename\n",
    "        \n",
    "        with open(analysis_file, 'w') as f:\n",
    "            json.dump(analysis, f, indent=2)\n",
    "        \n",
    "        # Display comprehensive summary\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DOCTR MODEL PERFORMANCE ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Basic Performance\n",
    "        print(f\"\\nBasic Performance:\")\n",
    "        print(f\"Total Images: {analysis['summary']['total_images']}\")\n",
    "        print(f\"Completed: {analysis['summary']['completed']}\")\n",
    "        print(f\"Errors: {analysis['summary']['errors']}\")\n",
    "        print(f\"Spatial Extraction Successful: {analysis['summary']['spatial_extraction_successful']}\")\n",
    "        print(f\"Work Order Accuracy: {analysis['summary']['work_order_accuracy']:.2%}\")\n",
    "        print(f\"Total Cost Accuracy: {analysis['summary']['total_cost_accuracy']:.2%}\")\n",
    "        print(f\"Average CER: {analysis['summary']['average_cer']:.3f}\")\n",
    "        \n",
    "        # Document Type Detection\n",
    "        print(f\"\\nDocument Type Detection:\")\n",
    "        doc_detection = analysis['summary']['document_type_detection']\n",
    "        print(f\"Invoice Detected: {doc_detection['invoice_detected']}\")\n",
    "        print(f\"Estimate Detected: {doc_detection['estimate_detected']}\")\n",
    "        print(f\"Type Unknown: {doc_detection['type_unknown']}\")\n",
    "        \n",
    "        # Confidence Analysis\n",
    "        print(f\"\\nConfidence Analysis:\")\n",
    "        confidence = analysis['summary']['confidence_analysis']\n",
    "        print(f\"Spatial Match Rate: {confidence['spatial_match_rate']:.2%}\")\n",
    "        print(f\"Work Order Confidence Accuracy: {confidence['work_order_confidence_accuracy']:.2%}\")\n",
    "        print(f\"Total Cost Confidence Accuracy: {confidence['total_cost_confidence_accuracy']:.2%}\")\n",
    "        \n",
    "        # Performance Metrics\n",
    "        print(f\"\\nPerformance Metrics:\")\n",
    "        for metric, value in analysis['performance_metrics'].items():\n",
    "            if 'rate' in metric:\n",
    "                print(f\"- {metric.replace('_', ' ').title()}: {value:.2%}\")\n",
    "            else:\n",
    "                print(f\"- {metric.replace('_', ' ').title()}: {value:.2f}\")\n",
    "        \n",
    "        # Document Type Performance\n",
    "        print(f\"\\nPerformance by Document Type:\")\n",
    "        for doc_type, perf in analysis['document_type_performance'].items():\n",
    "            if perf['count'] > 0:\n",
    "                print(f\"  {doc_type.title()} (n={perf['count']}):\")\n",
    "                print(f\"    Work Order: {perf['work_order_accuracy']:.2%}\")\n",
    "                print(f\"    Total Cost: {perf['total_cost_accuracy']:.2%}\")\n",
    "        \n",
    "        # Error Categories\n",
    "        print(f\"\\nWork Order Error Categories:\")\n",
    "        for category, count in analysis['error_categories']['work_order'].items():\n",
    "            print(f\"  {category}: {count}\")\n",
    "        \n",
    "        print(f\"\\nTotal Cost Error Categories:\")\n",
    "        for category, count in analysis['error_categories']['total_cost'].items():\n",
    "            print(f\"  {category}: {count}\")\n",
    "        \n",
    "        print(f\"\\nDetailed analysis saved to: {analysis_file}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d30d3f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Run Analysis\n",
    "Generate and display analysis of raw OCR results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4aa6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "analysis_results = run_analysis() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
