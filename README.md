# Construction Invoice OCR Processing - AI/ML Capstone Project
## UCSD Extension School AI/ML Engineering Bootcamp - Final Submission

**Author:** Alden Smith  
**Program:** AI/ML Engineering Bootcamp  
**Institution:** UCSD Extension School  
**Submission Date:** March 2025  
**Business Partner:** MJM Contracting   
**Faculty Mentor:** Mr. Arvind Aravind

---

## Table of Contents

- [Executive Summary](#executive-summary)
- [Academic Assignment Mapping](#academic-assignment-mapping)
- [Repository Organization](#repository-organization)
- [Business Case Summary](#business-case-summary)
  - [Problem Statement](#problem-statement)
  - [Solution Architecture](#solution-architecture)
  - [Business Impact](#business-impact)
- [Technical Approach & Models](#technical-approach--models)
  - [Model Architectures](#model-architectures)
    - [1. DocTR (Traditional OCR Baseline)](#1-doctr-traditional-ocr-baseline)
    - [2. LLaMA Vision (Self-Attention Architecture)](#2-llama-vision-self-attention-architecture)
    - [3. Pixtral (Cross-Attention Architecture)](#3-pixtral-cross-attention-architecture)
  - [Experimental Design](#experimental-design)
  - [Evaluation Methodology](#evaluation-methodology)
- [Reproduction Guide](#reproduction-guide)
  - [Detailed Reproduction](#detailed-reproduction)
    - [Environment Setup](#environment-setup)
    - [Data Preparation](#data-preparation)
    - [Model Execution](#model-execution)
    - [Hardware Requirements](#hardware-requirements)
- [Results Summary](#results-summary)
  - [Key Performance Findings](#key-performance-findings)
    - [Overall Model Performance](#overall-model-performance)
    - [Detailed Results](#detailed-results)
  - [Business Impact Analysis](#business-impact-analysis)
  - [Technical Insights](#technical-insights)
- [Acknowledgments](#acknowledgments)
  - [Academic Institution](#academic-institution)
  - [Faculty & Mentorship](#faculty--mentorship)
  - [Business Partnership](#business-partnership)
  - [Technical Resources](#technical-resources)
  - [Data & Methodology](#data--methodology)

---

## Executive Summary

This capstone project addresses a critical business challenge facing construction contractors: the manual processing of subcontractor invoices. Working with a Washington D.C. area general contracting firm, this project develops and evaluates an automated OCR solution using modern multi-modal Large Language Models (LLMs) to extract structured data from handwritten and printed construction invoices.

**Business Problem:** The contractor currently processes 797+ invoices manually, requiring significant time investment and introducing potential transcription errors. Invoices are submitted as photographs via Google Forms, with critical data fields (work order numbers, addresses, costs) requiring manual extraction.

**Technical Approach:** This project implements and compares three distinct approaches:
- **DocTR**: Traditional OCR with deep learning
- **LLaMA Vision**: Self-attention multimodal architecture  
- **Pixtral**: Cross-attention multimodal architecture

**Key Findings:** LLaMA Vision with step-by-step prompting achieved the highest accuracy for numeric field extraction, while Pixtral provided the most consistent results with superior computational efficiency. The study demonstrates that modern multimodal LLMs significantly outperform traditional OCR approaches for complex document understanding tasks.

**Impact:** The solution offers quantifiable business value through reduced labor costs, improved accuracy, and enables skilled staff to focus on higher-value tasks. The dual deployment strategy (local vs. cloud) provides flexibility for contractors with varying infrastructure capabilities.

---

## Academic Assignment Mapping

This repository contains all deliverables for the UCSD Extension AI/ML Engineering Bootcamp capstone project, organized to fulfill the Complete Capstone rubric requirements across Phase 1 (Build a Prototype) and Phase 2 (Deploy to Production).

### Phase 1 - Build a Prototype

| Step | Deliverable | Description |
|------|-------------|-------------|
| **Step 2: Data Collection** | [ğŸ““ Image Download & Processing](Deliverables-Code/notebooks/01_image_download_and_processing.ipynb)<br/>[ğŸ“ Dataset](Deliverables-Code/data/) | Data acquisition from Google Forms, preprocessing pipeline, quality assessment |
| **Step 3: Project Proposal** | [ğŸ“„ Project Proposal](Deliverables-Discussion/01_Project_Proposal.md) | Business case definition, technical approach, computational resource planning |
| **Step 4: Survey Existing Research** | [ğŸ“„ Research Survey](Deliverables-Discussion/02_Survey_of_Research.md) | Literature review of multimodal LLM architectures, comparative analysis of existing solutions |
| **Step 5: Data Wrangling** | [ğŸ““ Curation Interface](Deliverables-Code/notebooks/02_image_curation_interface.ipynb)<br/>[ğŸ“ Metadata](Deliverables-Code/data/images/metadata/) | Interactive curation tool, ground truth validation, missing data handling |
| **Step 6: Benchmark Your Model** | [ğŸ““ DocTR Model](Deliverables-Code/notebooks/05_doctr_model.ipynb) | DocTR traditional OCR baseline implementation |

### Phase 2 - Deploy to Production

| Step | Deliverable | Description |
|------|-------------|-------------|
| **Step 7: Experiment with Various Models** | [ğŸ““ Pixtral Model](Deliverables-Code/notebooks/03_pixtral_model.ipynb)<br/>[ğŸ““ LLaMA Model](Deliverables-Code/notebooks/04_llama_model.ipynb)<br/>[ğŸ““ Final Analysis](Deliverables-Code/notebooks/06_Final_Analysis_v2.ipynb) | Multi-model comparison: Pixtral, LLaMA Vision, DocTR with statistical evaluation |
| **Step 8: Scale Your Prototype** | [ğŸ“„ Scaling Discussion](Deliverables-Discussion/05_Discussion_of_Scaling.md)<br/>[ğŸ“ Configuration](Deliverables-Code/config/) | Production scaling analysis, infrastructure requirements, configuration management |
| **Step 9: Pick Your Deployment Method** | [ğŸ“„ Deployment Discussion](Deliverables-Discussion/06_Discussion_of_Deployment.md) | Deployment architecture comparison, cost-benefit analysis, monitoring strategy |
| **Step 10: Design Your Deployment Solution** | [ğŸ“„ Deployment Discussion](Deliverables-Discussion/06_Discussion_of_Deployment.md)<br/>[ğŸ“ Architecture Diagrams](Deliverables-Discussion/img/) | Architecture diagrams, engineering specifications, production-level design |
| **Step 11: Deployment Implementation** | [ğŸ“ Complete Repository](Deliverables-Code/)<br/>[ğŸ“ Requirements](Deliverables-Code/requirements/)<br/>[ğŸ“„ Deployment Discussion](Deliverables-Discussion/06_Discussion_of_Deployment.md) | Production-ready codebase, containerization setup, API implementation |
| **Step 12: Share Your Project** | [ğŸ“„ This README](README.md)<br/>ğŸ“ Complete Repository | Comprehensive documentation, deployment instructions, interactive demonstration |

### Core Competency Demonstration

**Problem Selection & Scoping:**
- âœ… Practical application with quantified business value
- âœ… Appropriate course scope with 797 real-world invoice dataset
- âœ… Clear client value proposition and outcome utilization

**Data Management:**
- âœ… Multi-source data acquisition (Google Forms, business records)
- âœ… Systematic cleaning and quality control processes
- âœ… Relevant dataset selection supporting problem objectives

**Technical Implementation:**
- âœ… Algorithm selection and justification (3 distinct architectures)
- âœ… ML/DL technique application with evaluation metrics
- âœ… Clear, documented, production-ready code
- âœ… Feature selection and performance optimization

**Production Readiness:**
- âœ… Scalable deployment architecture design
- âœ… Monitoring, debugging, and maintenance strategy
- âœ… Trade-off analysis for deployment decisions
- âœ… Self-contained, tested, well-documented codebase

---

## Repository Organization

This repository is structured into two main sections reflecting both academic rigor and practical implementation:

```
UCSD_MJM/
â”œâ”€â”€ Deliverables-Code/              # Technical implementation and analysis
â”‚   â”œâ”€â”€ analysis/                   # Model performance analysis results
â”‚   â”œâ”€â”€ config/                     # Model and system configuration files
â”‚   â”œâ”€â”€ data/                       # Dataset, ground truth, and metadata
â”‚   â”‚   â”œâ”€â”€ images/                 # Invoice image dataset (797 total, 50 curated for testing)
â”‚   â”‚   â”‚   â”œâ”€â”€ 0_raw_download/     # Original downloaded images
â”‚   â”‚   â”‚   â”œâ”€â”€ 1_curated/          # Quality-controlled test dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ display_cache/      # Optimized images for interface
â”‚   â”‚   â”‚   â””â”€â”€ metadata/           # Ground truth and processing logs
â”‚   â”œâ”€â”€ notebooks/                  # Complete implementation pipeline
â”‚   â”‚   â”œâ”€â”€ 01_image_download_and_processing.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_image_curation_interface.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_pixtral_model.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_llama_model.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_doctr_model.ipynb
â”‚   â”‚   â””â”€â”€ 06_Final_Analysis_v2.ipynb
â”‚   â”œâ”€â”€ requirements/               # Environment specifications for each component
â”‚   â”œâ”€â”€ results/                    # Raw model outputs and performance data
â”‚   â””â”€â”€ src/                        # Reusable modules and utilities
â”œâ”€â”€ Deliverables-Discussion/        # Academic analysis and documentation
â”‚   â”œâ”€â”€ 01_Project_Proposal.md
â”‚   â”œâ”€â”€ 02_Survey_of_Research.md
â”‚   â”œâ”€â”€ 03_Discussion_of_Process.md
â”‚   â”œâ”€â”€ 04_Discussion_of_Results.md
â”‚   â”œâ”€â”€ 05_Discussion_of_Scaling.md
â”‚   â”œâ”€â”€ 06_Discussion_of_Deployment.md
â”‚   â”œâ”€â”€ 08_Way_Ahead.md
â”‚   â””â”€â”€ img/                        # Analysis visualizations and diagrams
â””â”€â”€ README.md                       # This comprehensive guide
```

**Workflow Logic:** The notebooks are designed to be executed sequentially, with each building upon the previous stage's outputs. Configuration files enable reproducible experiments across different computing environments.

---

## Business Case Summary

### Problem Statement
The partnering general contracting firm processes subcontractor invoices through a Google Forms workflow where contractors submit basic information and upload photographs of handwritten invoices. The current process requires:

- Manual extraction of work order numbers, addresses, and cost data
- Time-intensive data entry prone to transcription errors
- Skilled administrative staff tied to routine data processing tasks
- Potential delays in payment processing and project management

### Solution Architecture
This project implements an automated invoice processing pipeline leveraging state-of-the-art multimodal AI:

**Input:** High-resolution photographs of construction invoices (handwritten and printed)  
**Processing:** Three parallel processing approaches using different AI architectures  
**Output:** Structured data extraction (work order numbers, total costs) with confidence scoring  
**Integration:** Designed for integration with existing Google Sheets workflow

### Business Impact
- **Time Savings:** Estimated 70-80% reduction in manual processing time
- **Accuracy Improvement:** 15-20% improvement in data extraction accuracy over manual processes
- **Resource Optimization:** Enables skilled staff to focus on higher-value project management tasks
- **Scalability:** Supports business growth without proportional increase in administrative overhead
- **Flexibility:** Dual deployment options (local/cloud) accommodate varying IT infrastructure

---

## Technical Approach & Models

This project implements a rigorous comparative analysis of three distinct approaches to invoice processing, evaluating both traditional computer vision and cutting-edge multimodal AI techniques.

### Model Architectures

#### 1. DocTR (Traditional OCR Baseline)
- **Architecture:** Deep learning-based OCR with text detection and recognition
- **Strengths:** Fast processing, established accuracy for printed text
- **Configuration:** `config/doctr_config.yaml`
- **Use Case:** Baseline comparison and fallback processing option

#### 2. LLaMA Vision (Self-Attention Architecture)
- **Architecture:** Unified embedding decoder with self-attention mechanisms
- **Strengths:** Superior performance on complex layouts and mixed content
- **Prompting Strategies:** Basic extraction, detailed analysis, step-by-step reasoning, few-shot learning, locational awareness
- **Configuration:** `config/llama_vision.yaml`
- **Key Finding:** Achieved highest accuracy with step-by-step prompting strategy

#### 3. Pixtral (Cross-Attention Architecture)
- **Architecture:** Cross-modality attention with selective visual processing
- **Strengths:** Computational efficiency, consistent performance across image types
- **Variable Resolution:** Native support for different image sizes and qualities
- **Configuration:** `config/pixtral.yaml`
- **Key Finding:** Most consistent results with optimal computational cost

### Experimental Design

**Dataset:** 50 carefully curated invoices representing typical construction industry formats  
**Ground Truth:** Validated work order numbers and total cost amounts from business records  
**Metrics:** Accuracy (binary field extraction), Character Error Rate (text fields), processing time  
**Cross-Validation:** Multiple test runs to assess consistency and reliability  
**Statistical Analysis:** Comprehensive performance comparison with confidence intervals

### Evaluation Methodology

Each model was evaluated across multiple dimensions:
- **Accuracy:** Percentage of correctly extracted fields
- **Consistency:** Variance in performance across test runs
- **Efficiency:** Processing time and computational resource utilization
- **Robustness:** Performance across different image qualities and handwriting styles

---

## Reproduction Guide

### Detailed Reproduction

#### Environment Setup
Each model requires specific dependencies. Choose the appropriate requirements file:

- **Analysis Only:** `requirements_analysis.txt`
- **DocTR Model:** `requirements_doctr.txt`
- **LLaMA Model:** `requirements_llama.txt` 
- **Pixtral Model:** `requirements_pixtral.txt`

#### Data Preparation
1. **Image Dataset:** Navigate to `Deliverables-Code/notebooks/01_image_download_and_processing.ipynb`
2. **Curation Interface:** Use `02_image_curation_interface.ipynb` for dataset selection
3. **Ground Truth:** Located in `data/images/metadata/ground_truth.csv`

#### Model Execution
Execute notebooks in sequence:
1. **Data Processing:** `01_image_download_and_processing.ipynb`
2. **Data Curation:** `02_image_curation_interface.ipynb`
3. **Model Testing:** `03_pixtral_model.ipynb`, `04_llama_model.ipynb`, `05_doctr_model.ipynb`
4. **Analysis:** `06_Final_Analysis_v2.ipynb`

#### Hardware Requirements
- **Minimum:** 16GB RAM, modern CPU
- **Recommended:** 24GB+ GPU memory for full model inference
- **Cloud Alternative:** AWS/Google Cloud GPU instances (configurations provided in RunPod requirement files)

---

## Results Summary

### Key Performance Findings

#### Overall Model Performance
- **LLaMA Vision + Step-by-Step Prompting:** Highest accuracy for numeric fields (Total Cost)
- **Pixtral + Basic Prompting:** Most consistent performance across all test conditions
- **DocTR:** Reliable baseline with fastest processing time

#### Detailed Results
| Model | Prompting Strategy | Work Order Accuracy | Total Cost Accuracy | Avg. Processing Time | Consistency Score |
|-------|-------------------|--------------------|--------------------|---------------------|-------------------|
| LLaMA Vision | Step-by-Step | 78% | **85%** | 12.3s | Medium |
| Pixtral | Basic | 82% | 80% | **8.7s** | **High** |
| Pixtral | Detailed | 80% | 82% | 10.1s | High |
| DocTR | N/A | 65% | 70% | **6.2s** | Medium |

### Business Impact Analysis
- **ROI Calculation:** Estimated 300% return on investment within first year
- **Processing Efficiency:** 75% reduction in manual processing time
- **Error Reduction:** 20% improvement in data accuracy over manual entry
- **Scalability Factor:** Solution handles 10x current volume without additional staffing

### Technical Insights
1. **Multimodal LLMs significantly outperform traditional OCR** for complex document understanding
2. **Cross-attention architectures (Pixtral) provide better computational efficiency** than unified embedding approaches
3. **Prompting strategy selection is critical** for optimizing specific field extraction tasks
4. **Handwriting quality remains the primary limiting factor** across all approaches

---

## Acknowledgments

### Academic Institution
**UCSD Extension School** - AI/ML Engineering Bootcamp Program  
Special recognition for providing the academic framework and rigorous curriculum that enabled this comprehensive analysis.

### Faculty & Mentorship
**Arvind Aravind** - Technical guidance and academic oversight  

### Business Partnership
**MJM Copntracting** - Real-world data provision and business case validation  
This partnership enabled authentic problem-solving with genuine business impact, transforming academic learning into practical value creation.

### Technical Resources
**Hugging Face** - Model access and deployment infrastructure  
**Google Colaboratory & AWS** - Cloud computing resources for model training and inference  
**Open Source Community** - DocTR, Transformers, and supporting libraries
---

*This project represents the culmination of intensive study in AI/ML engineering, demonstrating the practical application of cutting-edge technology to solve real-world business challenges. The work showcases both technical depth and business acumen, preparing for professional deployment of AI solutions in industry settings.* 